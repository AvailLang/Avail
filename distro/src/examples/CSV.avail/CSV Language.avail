/*
 * CSV Language.avail
 * Copyright © 1993-2019, The Avail Foundation, LLC.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 * * Redistributions of source code must retain the above copyright notice, this
 *   list of conditions and the following disclaimer.
 *
 * * Redistributions in binary form must reproduce the above copyright notice,
 *   this list of conditions and the following disclaimer in the documentation
 *   and/or other materials provided with the distribution.
 *
 * * Neither the name of the copyright holder nor the names of the contributors
 *   may be used to endorse or promote products derived from this software
 *   without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

Module "CSV Language"
Extends
	"Avail" =
	(
		/* Some of the core Avail syntax. */
		"keyword lexer",
		"string token lexer",
		"operator lexer"
	)
Uses
	"Avail"
Names
	/* Build CSV records. */
	"CSV whitespace lexer",
	"CSV end of line lexer",
	"«…!»«…$‡,»…!",

	/* CSV data module processing. */
	"Reset CSV processor",
	"Display CSV(as a table«with headers»?)"
Body

/**
 * The number of columns allowed per record. This is determined by the column
 * count of the very first record, which is construed to be the header.
 *
 * @global "records" "natural number"
 */
columnCount : natural number;

/**
 * The records of CSV data. The first such record is the header; it names the
 * individual data fields. The subsequent records are actual data records.
 *
 * @global "records" "<string*…|>"
 */
records : <string+…|> := <>;

/**
 * An invalid-CSV-record exception indicates that a CSV record was invalid for
 * some reason.
 *
 * @type "invalid-CSV-record exception"
 * @supertype "exception"
 */
Explicit class "invalid-CSV-record exception" extends descriptive exception;

/**
 * Validate the specified CSV record. If no records have been previously
 * validated, then assume that the supplied record is the header and that it
 * specifies the expected column count. Reject the current parse on failure.
 *
 * @method "Validate_"
 * @param "record" "string+"
 *        A CSV record that includes at least one column.
 * @returns "⊤"
 */
Private method "Validate_" is
[
	record : string+
|
	// Get the size of the record.
	size ::= |record|;
	// Enforce the column count, if possible.
	If columnCount is assigned ∧ size ≠ columnCount then
	[
		Reject parse, expected:
			format "CSV record #“①” to have “②” columns (not “③”)"
			with |records| + 1, columnCount, size
	];
];

/**
 * Actually add the CSV record to {@global "records"}.
 *
 * @method "Append record_"
 * @param "record" "string+"
 * @returns "⊤"
 */
Private method "Append record_" is
[
	record : string+
|
	If columnCount is unassigned then [columnCount := |record|;];
	records ++= <record>;
];

"end-of-line marker" is a new atom;

/**
 * Add the CSV record to {@global "records"}.
 *
 * @method "«…$‡,»"
 * @param "pLeadingEOLs" "list phrase⇒((literal token⇒{end-of-line marker}ᵀ)*)"
 *        The leading {@method "end-of-line marker"}s, corresponding to line
 *        feed characters.
 * @param "record" "list phrase ⇒ ((literal token ⇒ string)+)"
 *        A {@type "list phrase" list} of {@type "literal token" literal} {@type
 *        "string"}s.
 * @param "pTrailingEOL" "literal phrase⇒(literal token⇒{end-of-line marker}ᵀ)"
 *        The trailing {@method "end-of-line marker"}.
 * @returns "expression as statement phrase"
 */
Public macro "«…!»«…$‡,»…!" is
[
	pLeadingEOLs : list phrase ⇒ ((literal token ⇒ {end-of-line marker}ᵀ)*),
	pRecord : list phrase ⇒ ((literal token ⇒ string)+),
	pTrailingEOL : literal phrase ⇒ (literal token ⇒ {end-of-line marker}ᵀ)
|
	// We know that the record comprises only literals, so evaluate it.
	record ::= map each column of evaluate pRecord through [column's value];
	Validate record;
	send $"Append record_" with «<‘record’>» : ⊤ → statement phrase
];

/**
 * Reset the state of the CSV processor. This should be called before linking
 * a new CSV data module.
 *
 * @method "Reset CSV processor"
 * @returns "⊤"
 */
Public method "Reset CSV processor" is
[
	Clear columnCount;
	records := <>;
];

/**
 * Compute the column metrics for the specified {@type "tuple"} of records.
 *
 * @method "column metrics for_"
 * @param "someRecords" "string*"
 *        Some CSV records.
 * @returns "<natural number…|>"
 *          The column metrics, i.e., the widths of the widest datum within each
 *          column.
 * @raises "invalid-CSV-record exception"
 *         If {@param "someRecords"} {@method "_is empty" is empty}.
 */
Private method "column metrics for_" is
[
	someRecords : <string+…|>
|
	/* There are no records, so raise an exception. */
	Raise an invalid-CSV-record exception with
		error message ::= "no records defined"
] : <natural number…|>;

/**
 * Compute the column metrics for the specified {@type "tuple"} of records.
 *
 * @method "column metrics for_"
 * @param "someRecords" "string+"
 *        A nonempty {@type "tuple"} of CSV records.
 * @returns "<natural number…|>"
 *          The column metrics, i.e., the widths of the widest datum within each
 *          column.
 * @raises "invalid-CSV-record exception"
 *         If {@param "someRecords"} {@method "_is empty" is empty}.
 */
Private method "column metrics for_" is
[
	someRecords : <string+…|1..>
|
	map each columnIndex in 1 to |someRecords[1]| through
	[
		max map each col in stripe someRecords at columnIndex through
			[1 max |col|]
	]
];

/**
 * Answer a variant of {@param "s"} that is left-aligned and padded to {@param
 * "fieldSize"} characters.
 *
 * @method "_padded to_character|characters"
 * @param "s" "string"
 *        An arbitrary string.
 * @param "fieldSize" "whole number"
 *        The size of the field after padding. This is the minimum possible
 *        field size for the result. The result might be longer if the size of
 *        {@param "s"} is greater than {@param "fieldSize"}.
 * @returns "string" A potentially padded field.
 */
Private method "_padded to_character|characters" is
[
	s : string,
	fieldSize : whole number
|
	s ++ (0 max fieldSize - |s| of ¢" ")
];

/**
 * Strengthen the result type to include only {@type "string"}s whose sizes are
 * at least the upper bound of {@param "fieldSize"}.
 *
 * @method "_padded to_character|characters"
 * @restricts "s" "string's type"
 * @restricts "fieldSize" "whole number's type"
 */
Semantic restriction "_padded to_character|characters" is
[
	s : string's type,
	fieldSize : whole number's type
|
	<character… | ⎣fieldSize⎦.. >
];

/**
 * Display the accumulated CSV records as a table.
 *
 * @method "Display CSV(as a table«with headers»?)"
 * @param "showHeader" "boolean"
 *        If {@method "true"}, then display the header and a separator row.
 *        If {@method "false"}, then only display the data records.
 * @returns "⊤"
 */
Public method "Display CSV(as a table«with headers»?)" is
[
	showHeaders : boolean
|
	/* The first record is the header, but the rest are data records. */
	dataRecords ::= records[2..];
	/* Compute the metrics for each column of the table. */
	metrics ::= column metrics for
		(if showHeaders then [records] else [dataRecords]);

	/* This is the text collector. */
	text : string := "";

	/* If the headers are desired, then accumulate them into the text collector.
	 * Also accumulate a separator row.
	 */
	If showHeaders then
	[
		record ::= records[1];
		text := left fold <""> ++ 1 to |record| through
			[
				index : natural number,
				headerSoFar : string
			|
				uppercased ::= uppercase record[index];
				headerSoFar
					++ (uppercased padded to metrics[index] characters)
					++ " "
			];
		text ++= "\n";
		text := left fold <text> ++ 1 to |record| through
			[
				index : natural number,
				textSoFar : string
			|
				textSoFar ++ metrics[index] of ¢- ++ " "
			];
		text ++= "\n";
	];

	/* Accumulate each of the data records into the text collector. */
	For each record of dataRecords do
	[
		text := left fold <text> ++ 1 to |record| through
			[
				index : natural number,
				textSoFar : string
			|
				textSoFar
					++ (record[index] padded to metrics[index] characters)
					++ " "
			];
		text ++= "\n";
	];

	/* Display the collected text. */
	Print: text;
];

// Define the lexers together, to keep their lexing effects transactional.
[
	/**
	 * Redefine whitespace to ignore line feeds.
	 *
	 * @lexer "CSV whitespace lexer"
	 * @param "source" "string"
	 *        The complete source text.
	 * @param "position" "real source position"
	 *        The position of the leading {@type "character"}.
	 * @param "line" "real source line number"
	 *        The line number of the leading {@type "character"}.
	 * @returns "{token+|}"
	 *          The possible lexes discovered at {@code "position"}.
	 */
	Lexer $"CSV whitespace lexer"
	when [c : character | c ∈ {¢" ", ¢"\t"}]
	is
	[
		source : string,
		position : real source position,
		line : real source line number
	|
		{<whitespace (source[position..position]) @ position:line>}
	];

	/**
	 * Convert line feed characters into occurrences of a special {@type
	 * "atom"}, for the purpose of eliminating the ambiguity in top-level
	 * parsing.
	 *
	 * @lexer "CSV end of line lexer"
	 * @param "source" "string"
	 *        The complete source text.
	 * @param "position" "real source position"
	 *        The position of the leading {@type "character"}.
	 * @param "line" "real source line number"
	 *        The line number of the leading {@type "character"}.
	 * @returns "{token+|}"
	 *          The possible lexes discovered at {@code "position"}.
	 */
	Lexer $"CSV end of line lexer"
	when [c : character | c = ¢"\n"]
	is
	[
		source : string,
		position : real source position,
		line : real source line number
	|
		{<`end-of-line marker` (source[position..position]) @ position:line>}
	];
]();
